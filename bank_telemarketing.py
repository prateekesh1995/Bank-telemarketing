# -*- coding: utf-8 -*-
"""bank Telemarketing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gkKdSrQGZF193mBBZuuEpQaurec5tOBO
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
files.upload()

dataset1=pd.read_csv("bank-full.csv")

dataset1.describe()

dataset1.head

dataset1.tail

condition=dataset1.poutcome=="other"
dataset2=dataset1.drop(dataset1[condition].index,axis=0,inplace=False)
condition1=dataset2.poutcome=="unknown"
dataset2=dataset2.drop(dataset2[condition1].index,axis=0,inplace=False)
condition2=dataset2.job=="unknown"
dataset2=dataset2.drop(dataset2[condition2].index,axis=0,inplace=False)
dataset2["education"].value_counts()
condition3=dataset2.education=="unknown"
dataset2=dataset2.drop(dataset2[condition3].index,axis=0,inplace=False)
dataset2["education"].value_counts()

from scipy.stats import zscore
dataset2[['balance']].mean()
dataset2[['balance']].mean()
dataset2['balance_outliers'] = dataset2['balance']
dataset2['balance_outliers']= zscore(dataset2['balance_outliers'])
dataset2["balance_outliers"]
condition1 = (dataset2['balance_outliers']>3) | (dataset2['balance_outliers']<-3 )

dataset3 = dataset2.drop(dataset2[condition1].index, axis = 0, inplace = False)
dataset3 = dataset2.drop(dataset2[condition1].index, axis = 0, inplace = False)
dataset3=dataset3.drop('contact',axis=1)
dataset3['duration']=dataset3['duration'].apply(lambda n:n/60).round(1)
dataset3
lst=[dataset3]
for column in lst:
  column.loc[column["month"]=="jan","month_int"]=1
  column.loc[column["month"]=="feb","month_int"]=2
  column.loc[column["month"]=="mar","month_int"]=3
  column.loc[column["month"]=="apr","month_int"]=4
  column.loc[column["month"]=="may","month_int"]=5
  column.loc[column["month"]=="jun","month_int"]=6
  column.loc[column["month"]=="jul","month_int"]=7
  column.loc[column["month"]=="aug","month_int"]=8
  column.loc[column["month"]=="sep","month_int"]=9
  column.loc[column["month"]=="oct","month_int"]=10
  column.loc[column["month"]=="nov","month_int"]=11
  column.loc[column["month"]=="dec","month_int"]=12
condition2=(dataset3["duration"]<5/60)
dataset4=dataset3.drop(dataset3[condition2].index,axis=0,inplace=False)
dataset4=dataset3.drop(dataset3[condition2].index,axis=0,inplace=False)

from scipy.stats import chi2_contingency
tbl1=pd.crosstab(dataset4["age"],dataset4["balance"])
chiqex1=chi2_contingency(tbl1)
chiqex1

from scipy.stats import chi2_contingency
tbl2=pd.crosstab(dataset4["duration"],dataset4["campaign"])
chiqex2=chi2_contingency(tbl2)
chiqex2

tbl2.plot(kind="bar")

"""Correlation Matrix"""

correlation=dataset4.corr()

correlation

dataset4

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()

dataset4["education"]

dataset4["education"]=le.fit_transform(dataset4["education"])

dataset4["education"]

dataset4["balance"]

dataset4["balance"]=le.fit_transform(dataset4["balance"])

dataset4["balance"]

dataset4["campaign"]=le.fit_transform(dataset4["campaign"])

dataset4["campaign"]

dataset4["duration"]=le.fit_transform(dataset4["duration"])

dataset4["duration"]

dataset4["job"]=dataset3["job"]

dataset4["job"]

dataset4["job"]=le.fit_transform(dataset4["job"])

dataset4["job"]

dataset4["marital"]=le.fit_transform(dataset4["marital"])
dataset4["default"]=le.fit_transform(dataset4["default"])
dataset4["housing"]=le.fit_transform(dataset4["housing"])
dataset4["loan"]=le.fit_transform(dataset4["loan"])
dataset4["poutcome"]=le.fit_transform(dataset4["poutcome"])
dataset4["y"]=le.fit_transform(dataset4["y"])
dataset4["month"]=le.fit_transform(dataset4["month"])

dataset4["month"]

from sklearn import decomposition
pca = decomposition.PCA(n_components = 2)
x = iris.data
pca = pca.fit(x)
x_dr= pca.transform(x)
x_dr = pd.DataFrame(x_dr)
x_dr.columns = ['PCA1','PCA2']
x_dr['labels'] = iris.target

from sklearn import decomposition
pca = decomposition.PCA(n_components = 5)
x=dataset4

pca=pca.fit(x)

x_dr=pca.transform(x)

x_dr=pd.DataFrame(x_dr)

x_dr

x_dr.columns=['PCA1','PCA2','PCA3','PCA4','PCA5']
x_dr = pd.DataFrame(data=x_dr,columns=['PCA1','PCA2','PCA3','PCA4','PCA5'])

x_dr.tail()

y=train_1['IsAlert']
x=train_1.iloc[:,3:30]
#Logistic Regression
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=123)
from sklearn.linear_model import LogisticRegression
lr=LogisticRegression(random_state=123)
lr.fit(x_train,y_train)
preds_lr= lr.predict(x_train)
from sklearn.metrics import confusion_matrix
cm_lr=confusion_matrix(y_train,preds_lr)

dataset4

#appl
y=dataset4['y']
x=x_dr.iloc[:,0:30]

x.shape

y

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.2,random_state=123)
from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train,y_train)
preds_lr= lr.predict(x_train)

dataset4.shape

dataset4.dtypes

from sklearn.metrics import confusion_matrix
cm_lr=confusion_matrix(y_train,preds_lr)

cm_lr#76.97%

pred_lr_test=lr.predict(x_test)
cm_logit=confusion_matrix(y_test,pred_lr_test)

cm_logit#78.5%

from sklearn.preprocessing import normalize
skew_scale=x_train.skew()
x_train_scale=normalize(x_train)
lr.fit(x_train_scale,y_train)
preds_lr_normal=lr.predict(x_train_scale)
cm_lr_scale=confusion_matrix(y_train,preds_lr_normal)

cm_lr_scale#76.14%

#f1_score
from sklearn.metrics import f1_score
f1_score_lr=f1_score(y_train,preds_lr_normal)
print(f1_score_lr)

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier()
dtc.fit(x_train,y_train)
preds_dtc=dtc.predict(x_train)

from sklearn.metrics import confusion_matrix
cm_dtc=confusion_matrix(y_train,preds_dtc)

cm_dtc

#f1_score
from sklearn.metrics import f1_score
f1_score_lr=f1_score(y_train,preds_dtc)
print(f1_score_lr)

#Decision tree for test
preds_dtc_test=dtc.predict(x_test)
cm_dtc_test=confusion_matrix(y_test,preds_dtc_test)
f1_score_lr_dct_tst=f1_score(y_test,preds_dtc_test)

f1_score_lr_dct_tst

cm_dtc_test#76.01%

from sklearn.ensemble import RandomForestClassifier
rdf=RandomForestClassifier()
rdf.fit(x_train,y_train)
preds_rdf=rdf.predict(x_train)
from sklearn.metrics import confusion_matrix
cm_rdf=confusion_matrix(y_train,preds_rdf)
from sklearn.metrics import f1_score
f1_score_rd=f1_score(y_train,preds_rdf)
print(f1_score_rd)
preds_rdf_test=rdf.predict(x_test)
cm_rdf_test=confusion_matrix(y_test,preds_rdf_test)
f1_score_lr_rdf_tst=f1_score(y_test,preds_rdf_test)
print(f1_score_lr_rdf_tst)

from sklearn import svm
SVC=svm.SVC(gamma='auto',C=1.5)
SVC.fit(x_train,y_train)
preds_svm=SVC.predict(x_train)
cm_svc=confusion_matrix(y_train,preds_svm)
f1score_svc=f1_score(y_train,preds_svm)
print(f1score_svc)
preds_svm_test=SVC.predict(x_test)
cm_svm_test=confusion_matrix(y_test,preds_svm_test)
f1_score_svm_tst=f1_score(y_test,preds_svm_test)
print(f1_score_svm_tst)

